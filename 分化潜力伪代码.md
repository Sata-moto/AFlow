这非常清晰。你不仅定义了评估的场景（第 $i$ 轮，全量数据集），还给出了三个极其精确的**“分化指征”**。

这三个指标实际上分别代表了：**整体性能（Baseline）**、**局部召回率（Recall）** 和 **内部贡献度（Precision/Contribution）**。

基于这三点，我为你设计了**“优势特征提取算法” (Dominant Feature Extraction Algorithm)**。这个算法的核心在于寻找那些**“对工作流总分贡献巨大，且表现显著优于全局水平”**的子领域。

------

### 2.3.1 分化算子对象选择算法：优势特征提取模型

#### 1. 符号与指标定义

设当前考虑的候选工作流为 $W$，数据集 $D$ 总大小为 $N$。

数据集包含 $K$ 类子问题。对于第 $k$ 类问题，数据集中共有 $N_k$ 个。

根据全量跑一遍的结果，我们可以得出工作流 $W$ 的以下统计量：

- $C_k$：$W$ 正确解决第 $k$ 类问题的数量。
- $C_{total}$：$W$ 正确解决的问题总数（即 $\sum C_k$）。

我们将你的**三个核心考量点**形式化为以下三个指标：

1. **指标 A：全局正确率 (Global Accuracy)**
    - 对应你的点1：“当前工作流的正确率”。
    - $$Acc_{global} = \frac{C_{total}}{N}$$
    - **含义：** 这是基准线。如果某个子领域的表现不能显著超过这个基准线，就没有分化的必要。
2. **指标 B：子问题召回率 (Category Recall)**
    - 对应你的点2：“所解决问题中各子问题所占总的数据集中对应子问题数的比例”。
    - $$Recall_k = \frac{C_k}{N_k}$$
    - **含义：** 衡量 $W$ 在该特定领域的“统治力”。值越高，说明 $W$ 越有潜力成为该领域的专家。
3. **指标 C：子问题贡献度 (Category Contribution)**
    - 对应你的点3：“所解决问题中各子问题所占解决问题数的比例”。
    - $$Contrib_k = \frac{C_k}{C_{total}}$$
    - **含义：** 衡量该类问题在 $W$ 的“功劳簿”上的比重。如果 $Contrib_k$ 很高，说明 $W$ 的主要价值就是为了解决 $k$ 类问题存在的。

------

#### 2. 分化潜力计算公式

我们定义工作流 $W$ 的**分化潜力 (Split Potential)** 为其在所有子问题类别中，计算出的最大**“优势增益”**。

$$Score_{split}(W) = \max_{k} \left[ \underbrace{Contrib_k}_{\text{权重}} \cdot (\underbrace{Recall_k - Acc_{global}}_{\text{相对优势}}) \right]$$

**公式设计的物理含义解释：**

- **$(Recall_k - Acc_{global})$：** 这是**“特化红利”**。
    - 如果某类问题的解决率 ($Recall_k$) 远高于整体正确率 ($Acc_{global}$)，说明 $W$ 在这个问题上是被“由于处理其他问题而导致平均分拉低”的。
    - 如果差值 $\le 0$，说明在该领域表现平平，没有分化价值。
- **$Contrib_k$：** 这是**“身份确认”**。
    - 即使某类问题表现很好，但如果它只占工作流成功案例的极小一部分（$Contrib_k \approx 0$），说明它不是该工作流的主营业务，分化它对整体系统贡献不大。
    - 只有当某类问题既表现好，又是工作流的主要得分来源时，分化才有意义。

------

#### 3. 算法执行流程与伪代码

这个过程在第 $i$ 轮迭代中，对当前群体中的每一个工作流执行。

**前提：** 数据集各类的总数 $N_k$ 已知。

Python

```
def select_workflow_to_split(workflows, dataset_meta):
    """
    dataset_meta: {"A": 100, "B": 50...} 存储每类问题的总数 N_k
    total_problems (N): sum(dataset_meta.values())
    """
    candidates = []

    for W in workflows:
        # 1. 获取运行统计 (需要全量跑一遍)
        # correct_counts = {"A": 答对A的数量, "B": 答对B的数量...}
        correct_counts = W.last_run_stats 
        
        c_total = sum(correct_counts.values())
        
        # 边界处理：如果一个题都没做对，该工作流无分化价值，直接跳过
        if c_total == 0:
            continue

        # --- 计算指标 1: 全局正确率 ---
        acc_global = c_total / total_problems 
        
        # 寻找该工作流最具分化潜力的“主攻方向”
        max_k_score = -1.0
        
        for k, n_k in dataset_meta.items():
            if n_k == 0: continue
            
            c_k = correct_counts.get(k, 0)
            
            # --- 计算指标 2: 子问题召回率 (Recall) ---
            recall_k = c_k / n_k
            
            # 只有当 局部表现 > 全局表现 时才考虑
            if recall_k > acc_global:
                
                # --- 计算指标 3: 子问题贡献度 (Contribution) ---
                contrib_k = c_k / c_total
                
                # --- 核心公式 ---
                score_k = contrib_k * (recall_k - acc_global)
                
                if score_k > max_k_score:
                    max_k_score = score_k
        
        # 记录该工作流的最终得分
        # 如果 max_k_score 仍为负(所有子类都比平均差)，则置为 0
        final_score = max(0.0, max_k_score)
        
        candidates.append(final_score)

    # 4. 基于 Softmax 的概率选择
    # 使用前面定义的 p_split 逻辑选出的操作是"分化"，现在要选"对象"
    # 这里依然建议使用轮盘赌，避免确定性陷阱
    selected_index = softmax_selection(candidates)
    
    return workflows[selected_index]
```

------

#### 4. 数值案例推演（验证合理性）

假设 $N=100$。A类50题 ($N_A=50$)，B类50题 ($N_B=50$)。

场景一：典型的“偏科专家”（高分化价值）

工作流 $W_1$：答对 40 个 A，答对 10 个 B。

- $C_{total} = 50$
- **1. 全局正确率 $Acc_{global}$** = $50/100 = \mathbf{0.5}$
- **针对 A 类：**
    - $Recall_A = 40/50 = 0.8$
    - $Contrib_A = 40/50 = 0.8$
    - $Score_A = 0.8 \times (0.8 - 0.5) = 0.8 \times 0.3 = \mathbf{0.24}$
- **针对 B 类：**
    - $Recall_B = 10/50 = 0.2$
    - $Contrib_B = 10/50 = 0.2$
    - $Score_B = 0.2 \times (0.2 - 0.5) = -0.06$
- **最终得分：** $\mathbf{0.24}$

场景二：典型的“平庸混合体”（低分化价值）

工作流 $W_2$：答对 25 个 A，答对 25 个 B。

- $C_{total} = 50$
- **1. 全局正确率 $Acc_{global}$** = $50/100 = \mathbf{0.5}$
- **针对 A 类：**
    - $Recall_A = 25/50 = 0.5$
    - $Score_A = 0.5 \times (0.5 - 0.5) = \mathbf{0}$
- **最终得分：** $\mathbf{0}$

结果分析：

虽然 $W_1$ 和 $W_2$ 的总分完全一样（都是50分），但算法成功识别出 $W_1$ 具有极高的分化价值（因为它是被 B 类拖累的 A 类专家），而 $W_2$ 只是单纯的平庸，拆分它毫无意义。

这完美符合你的三个考量点设计。