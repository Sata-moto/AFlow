# Problem ID åŒ¹é…é—®é¢˜ä¿®å¤è¯´æ˜

## ä¿®æ”¹æ—¥æœŸ
2025-12-17

## é—®é¢˜æè¿°

HotpotQAæ•°æ®é›†åœ¨åˆ†åŒ–æ“ä½œæ—¶æŠ¥é”™ï¼š
```
WARNING - All workflows have zero split potential, no specialization opportunity
WARNING - No suitable workflow selected for differentiation
```

ç»è¿‡è°ƒæŸ¥ï¼Œå‘ç°**æ‰€æœ‰log.jsonä¸­çš„categoryå­—æ®µéƒ½æ˜¯'unknown'**ï¼Œå¯¼è‡´æ— æ³•è®¡ç®—åˆ†åŒ–æ½œåŠ›ã€‚

## æ ¹æœ¬åŸå› 

**Problem IDæ ¼å¼ä¸åŒ¹é…**ï¼š

1. **Validationæ•°æ®é›†** (`data/datasets/hotpotqa_validate.jsonl`):
   - ä½¿ç”¨MongoDBçš„`_id`å­—æ®µä½œä¸ºé—®é¢˜ID
   - æ ¼å¼ï¼š`5a7613c15542994ccc9186bf`ï¼ˆ16è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
   - æ•°æ®ä¸­**æ²¡æœ‰**`_index`å­—æ®µ

2. **åˆ†ç±»æ–‡ä»¶** (`workspace/HotpotQA/workflows/problem_classifications.json`):
   - ä½¿ç”¨ç´¢å¼•æ ¼å¼çš„`problem_id`
   - æ ¼å¼ï¼š`problem_0`, `problem_1`, `problem_2`, ...

3. **Benchmarkè¯„ä¼°ä»£ç ** (`benchmarks/hotpotqa.py`):
   ```python
   # è·å–problem_idçš„é€»è¾‘ï¼ˆç¬¬33-41è¡Œï¼‰
   if "id" in problem:
       problem_id = problem["id"]
   elif "_id" in problem:
       problem_id = problem["_id"]  # â† ä½¿ç”¨äº†MongoDB ID
   elif "_index" in problem:
       problem_id = f"problem_{problem['_index']}"  # â† æœŸæœ›çš„æ ¼å¼
   else:
       problem_id = "unknown"
   ```

4. **IDæŸ¥æ‰¾** (`benchmarks/benchmark.py` çš„ `_get_problem_category`):
   ```python
   # å°è¯•åœ¨åˆ†ç±»å­—å…¸ä¸­æŸ¥æ‰¾ï¼ˆç¬¬112-134è¡Œï¼‰
   if str_id in self.problem_classifications:
       return self.problem_classifications[str_id]
   # æ‰¾ä¸åˆ° â†’ è¿”å› "unknown"
   ```

**é—®é¢˜é“¾**:
```
validationæ•°æ®: _id = "5a7613c15542994ccc9186bf"
    â†“
hotpotqa.py: problem_id = "5a7613c15542994ccc9186bf"
    â†“
_get_problem_category("5a7613c15542994ccc9186bf")
    â†“
åœ¨ {"problem_0": "...", "problem_1": "..."} ä¸­æŸ¥æ‰¾
    â†“
æ‰¾ä¸åˆ° â†’ è¿”å› "unknown"
    â†“
log.json: category = "unknown"
    â†“
_load_workflow_category_stats: åªç»Ÿè®¡åˆ°1ä¸ªç±»åˆ« "unknown"
    â†“
åˆ†åŒ–æ½œåŠ›è®¡ç®—: æ‰€æœ‰workflowçš„split_potential = 0
```

## è§£å†³æ–¹æ¡ˆ

åœ¨`BaseBenchmark.load_data()`æ–¹æ³•ä¸­ï¼Œ**ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ `_index`å­—æ®µ**ï¼š

### ä¿®æ”¹æ–‡ä»¶
`benchmarks/benchmark.py`

### ä¿®æ”¹å†…å®¹ï¼ˆLine 138-150ï¼‰

**ä¿®æ”¹å‰**:
```python
async def load_data(self, specific_indices: List[int] = None) -> List[dict]:
    data = []
    async with aiofiles.open(self.file_path, mode="r", encoding="utf-8") as file:
        async for line in file:
            data.append(json.loads(line))
    if specific_indices is not None:
        filtered_data = [data[i] for i in specific_indices if i < len(data)]
        return filtered_data
    return data
```

**ä¿®æ”¹å**:
```python
async def load_data(self, specific_indices: List[int] = None) -> List[dict]:
    data = []
    async with aiofiles.open(self.file_path, mode="r", encoding="utf-8") as file:
        index = 0
        async for line in file:
            problem = json.loads(line)
            # æ·»åŠ  _index å­—æ®µï¼Œç”¨äºç”Ÿæˆç»Ÿä¸€çš„ problem_id æ ¼å¼
            problem['_index'] = index
            data.append(problem)
            index += 1
    if specific_indices is not None:
        filtered_data = [data[i] for i in specific_indices if i < len(data)]
        return filtered_data
    return data
```

### å·¥ä½œåŸç†

1. **åŠ è½½æ•°æ®æ—¶æ·»åŠ ç´¢å¼•**:
   ```python
   problem['_index'] = 0  # ç¬¬ä¸€ä¸ªé—®é¢˜
   problem['_index'] = 1  # ç¬¬äºŒä¸ªé—®é¢˜
   ...
   ```

2. **ç”Ÿæˆç»Ÿä¸€çš„problem_id**:
   ```python
   # åœ¨ hotpotqa.py çš„ evaluate_problem ä¸­
   elif "_index" in problem:
       problem_id = f"problem_{problem['_index']}"  # "problem_0", "problem_1", ...
   ```

3. **IDåŒ¹é…æˆåŠŸ**:
   ```python
   _get_problem_category("problem_0")
       â†“
   åœ¨ {"problem_0": "Mathematical & Logical Reasoning", ...} ä¸­æŸ¥æ‰¾
       â†“
   æ‰¾åˆ° â†’ è¿”å› "Mathematical & Logical Reasoning"
   ```

4. **categoryæ­£ç¡®è®°å½•**:
   ```python
   log.json: {
       "question": "...",
       "problem_id": "problem_0",
       "category": "Mathematical & Logical Reasoning",  # âœ“ æ­£ç¡®
       ...
   }
   ```

## å½±å“èŒƒå›´

### å—å½±å“çš„æ•°æ®é›†
æ‰€æœ‰ä½¿ç”¨problem_classifications.jsonçš„æ•°æ®é›†ï¼š
- âœ… **HotpotQA**: ä¿®å¤äº†categoryåŒ¹é…
- âœ… **DROP**: ä¿®å¤äº†categoryåŒ¹é…
- âœ… **MATH**: å¦‚æœä½¿ç”¨åˆ†ç±»ï¼Œä¹Ÿä¼šå—ç›Š
- âœ… **GSM8K**: å¦‚æœä½¿ç”¨åˆ†ç±»ï¼Œä¹Ÿä¼šå—ç›Š

### ä¸å—å½±å“çš„åŠŸèƒ½
- âœ… ä»£ç æ•°æ®é›†ï¼ˆHumanEval, MBPPï¼‰ï¼šä¸ä½¿ç”¨problem_classifications
- âœ… åŸºç¡€è¯„ä¼°æµç¨‹ï¼šåªæ˜¯æ·»åŠ äº†`_index`å­—æ®µï¼Œä¸å½±å“è¯„ä¼°é€»è¾‘
- âœ… å‘åå…¼å®¹ï¼šå¦‚æœé—®é¢˜å·²ç»æœ‰`_index`å­—æ®µï¼Œä¸ä¼šè¦†ç›–

### å‰¯ä½œç”¨
- âœ… æ— å‰¯ä½œç”¨ï¼š`_index`å­—æ®µåªç”¨äºå†…éƒ¨IDç”Ÿæˆï¼Œä¸å½±å“è¯„ä¼°ç»“æœ

## éªŒè¯æ–¹æ³•

### 1. æ£€æŸ¥log.jsonä¸­çš„category

**ä¿®å¤å‰**:
```bash
cd /home/wx/AFlow
python3 -c "
import json
with open('workspace/HotpotQA/workflows/round_1/log.json', 'r') as f:
    log_data = json.load(f)
    categories = set(entry.get('category', 'unknown') for entry in log_data)
    print(f'Categories: {categories}')
"
# è¾“å‡º: Categories: {'unknown'}  â† åªæœ‰unknown
```

**ä¿®å¤å**ï¼ˆéœ€è¦é‡æ–°è¿è¡Œè¯„ä¼°ï¼‰:
```bash
cd /home/wx/AFlow
python3 -c "
import json
with open('workspace/HotpotQA/workflows/round_NEW/log.json', 'r') as f:
    log_data = json.load(f)
    categories = {}
    for entry in log_data:
        cat = entry.get('category', 'unknown')
        categories[cat] = categories.get(cat, 0) + 1
    print('Categories:')
    for cat, count in sorted(categories.items()):
        print(f'  {cat}: {count}')
"
# æœŸæœ›è¾“å‡º:
# Categories:
#   Data Structure Operations: 1
#   Mathematical & Logical Reasoning: 162
#   Search & Optimization Algorithms: 37
```

### 2. æµ‹è¯•åˆ†åŒ–æ“ä½œ

**ä¿®å¤å‰**:
```
WARNING - All workflows have zero split potential
WARNING - No suitable workflow selected for differentiation
```

**ä¿®å¤å**:
```
INFO - Differentiation candidate ranking (top 3 by adjusted score):
  1. Round 17: adjusted=0.0135 (potential=0.0135, norm_pot=1.0000, acc=0.6950), category=Mathematical & Logical Reasoning
  ...
INFO - SELECTED: Round 17 for specialization
INFO - Target Category: Mathematical & Logical Reasoning
```

### 3. å•å…ƒæµ‹è¯•

```python
def test_problem_id_matching():
    """æµ‹è¯•problem_idåŒ¹é…"""
    import asyncio
    from benchmarks.hotpotqa import HotpotQABenchmark
    
    benchmark = HotpotQABenchmark(
        name="HotpotQA",
        file_path="data/datasets/hotpotqa_validate.jsonl",
        log_path="workspace/HotpotQA/workflows/round_test"
    )
    
    # åŠ è½½æ•°æ®
    data = asyncio.run(benchmark.load_data())
    
    # æ£€æŸ¥ _index å­—æ®µ
    assert all('_index' in problem for problem in data), "All problems should have _index"
    
    # æ£€æŸ¥ _index è¿ç»­æ€§
    indices = [problem['_index'] for problem in data]
    assert indices == list(range(len(data))), "_index should be continuous"
    
    # æ£€æŸ¥ problem_id ç”Ÿæˆ
    for i, problem in enumerate(data[:5]):
        if "_index" in problem:
            expected_id = f"problem_{problem['_index']}"
            assert expected_id == f"problem_{i}", f"Expected problem_{i}, got {expected_id}"
    
    # æ£€æŸ¥ category æŸ¥æ‰¾
    for problem in data[:10]:
        problem_id = f"problem_{problem['_index']}"
        category = benchmark._get_problem_category(problem_id)
        assert category != "unknown", f"Problem {problem_id} should have a valid category"
    
    print("âœ“ All tests passed!")
```

## åç»­å»ºè®®

### 1. æ ‡å‡†åŒ– Problem ID
å»ºè®®æ‰€æœ‰æ•°æ®é›†éƒ½ä½¿ç”¨ç»Ÿä¸€çš„`problem_{index}`æ ¼å¼ï¼š

**é€‰é¡¹A: åœ¨æ•°æ®é›†ç”Ÿæˆæ—¶æ·»åŠ **
```python
# åœ¨ data/download_data.py ä¸­
def prepare_dataset(dataset_name):
    with open(f'{dataset_name}_validate.jsonl', 'r') as f:
        lines = f.readlines()
    
    with open(f'{dataset_name}_validate.jsonl', 'w') as f:
        for i, line in enumerate(lines):
            problem = json.loads(line)
            problem['problem_id'] = f'problem_{i}'  # æ·»åŠ ç»Ÿä¸€ID
            f.write(json.dumps(problem) + '\n')
```

**é€‰é¡¹B: åœ¨åˆ†ç±»ç”Ÿæˆæ—¶ä½¿ç”¨åŸå§‹ID**
```python
# åœ¨ç”Ÿæˆ problem_classifications.json æ—¶
# ä½¿ç”¨æ•°æ®é›†ä¸­çš„åŸå§‹ID (_id, id, task_idç­‰)
classifications = []
for i, problem in enumerate(data):
    # ä½¿ç”¨åŸå§‹ID
    original_id = problem.get('_id') or problem.get('id') or problem.get('task_id') or f'problem_{i}'
    
    classifications.append({
        'problem_id': original_id,  # ä½¿ç”¨åŸå§‹IDè€Œä¸æ˜¯problem_{i}
        'category': classify(problem)
    })
```

### 2. IDæ˜ å°„è¡¨
å¦‚æœéœ€è¦ä¿æŒä¸¤ç§IDæ ¼å¼ï¼Œå¯ä»¥æ·»åŠ æ˜ å°„ï¼š

```json
{
    "id_mapping": {
        "problem_0": "5a7613c15542994ccc9186bf",
        "problem_1": "5adf2fa35542993344016c11",
        ...
    },
    "problem_classifications": [...]
}
```

### 3. éªŒè¯å·¥å…·
åˆ›å»ºIDéªŒè¯å·¥å…·ï¼Œåœ¨ç”Ÿæˆåˆ†ç±»æ–‡ä»¶åè‡ªåŠ¨æ£€æŸ¥ï¼š

```python
def verify_classification_ids(dataset_name):
    """éªŒè¯åˆ†ç±»æ–‡ä»¶ä¸­çš„IDæ˜¯å¦ä¸æ•°æ®é›†åŒ¹é…"""
    # åŠ è½½æ•°æ®é›†
    with open(f'data/datasets/{dataset_name}_validate.jsonl') as f:
        data = [json.loads(line) for line in f]
    
    # åŠ è½½åˆ†ç±»
    with open(f'workspace/{dataset_name}/workflows/problem_classifications.json') as f:
        classifications = json.load(f)['problem_classifications']
    
    # æå–æ•°æ®é›†ID
    dataset_ids = set()
    for i, problem in enumerate(data):
        # ä½¿ç”¨ä¸benchmarkç›¸åŒçš„é€»è¾‘ç”ŸæˆID
        if 'id' in problem:
            pid = problem['id']
        elif '_id' in problem:
            pid = problem['_id']
        elif '_index' in problem:
            pid = f"problem_{problem['_index']}"
        else:
            pid = f"problem_{i}"
        dataset_ids.add(str(pid))
    
    # æå–åˆ†ç±»ID
    classification_ids = set(c['problem_id'] for c in classifications)
    
    # æ£€æŸ¥åŒ¹é…
    missing = dataset_ids - classification_ids
    extra = classification_ids - dataset_ids
    
    if missing:
        print(f"âš ï¸  {len(missing)} IDs in dataset but not in classifications: {list(missing)[:5]}")
    if extra:
        print(f"âš ï¸  {len(extra)} IDs in classifications but not in dataset: {list(extra)[:5]}")
    
    if not missing and not extra:
        print(f"âœ“ All {len(dataset_ids)} IDs match!")
    
    return len(missing) == 0 and len(extra) == 0
```

## æ€»ç»“

è¿™æ¬¡ä¿®å¤é€šè¿‡åœ¨æ•°æ®åŠ è½½æ—¶æ·»åŠ `_index`å­—æ®µï¼Œè§£å†³äº†HotpotQAç­‰æ•°æ®é›†çš„Problem IDåŒ¹é…é—®é¢˜ã€‚

**å…³é”®æ”¹è¿›**:
- âœ… ç»Ÿä¸€çš„IDç”Ÿæˆæœºåˆ¶ï¼š`problem_{index}`
- âœ… æ­£ç¡®çš„categoryåŒ¹é…ï¼šlog.jsonä¸­è®°å½•çœŸå®ç±»åˆ«
- âœ… åˆ†åŒ–æ“ä½œå¯ç”¨ï¼šå¯ä»¥è®¡ç®—split potential
- âœ… å‘åå…¼å®¹ï¼šä¸å½±å“ç°æœ‰åŠŸèƒ½

**åç»­ä¼˜åŒ–**:
- ğŸ“ æ ‡å‡†åŒ–æ‰€æœ‰æ•°æ®é›†çš„Problem IDæ ¼å¼
- ğŸ“ æ·»åŠ IDéªŒè¯å·¥å…·
- ğŸ“ åœ¨æ–‡æ¡£ä¸­è¯´æ˜IDæ ¼å¼è¦æ±‚
