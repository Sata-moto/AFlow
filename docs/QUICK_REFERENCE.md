# å¿«é€Ÿå‚è€ƒ (Quick Reference)

## æ–‡æ¡£ç‰ˆæœ¬
- **åˆ›å»ºæ—¥æœŸ**: 2025-12-15
- **é€‚ç”¨ç‰ˆæœ¬**: AFlow Enhanced Optimizer
- **ç›¸å…³æ–‡æ¡£**: å®Œæ•´æ–‡æ¡£é›†

---

## 1. æ ¸å¿ƒå…¬å¼é€ŸæŸ¥

### 1.1 åœæ»åº¦è®¡ç®—

```python
# åœæ»åº¦ (Plateau)
t = len(performance_history)
k = sliding_window_k  # é»˜è®¤: 3

if t < 2:
    plateau_t = 0.0
else:
    effective_k = min(k, t // 2)
    window = performance_history[-effective_k:]
    
    improvements = [window[i+1] - window[i] for i in range(len(window)-1)]
    avg_improvement = mean(improvements)
    
    plateau_t = (1 - avg_improvement / Îº) * 100
    plateau_t = clip(plateau_t, 0, 100)

# Îº (kappa): æ•æ„Ÿåº¦, é»˜è®¤ 80.0
```

**ç›´è§‚ç†è§£**:
- `plateau_t â‰ˆ 0`: æ€§èƒ½å¿«é€Ÿæå‡
- `plateau_t â‰ˆ 50`: æ€§èƒ½ç¼“æ…¢æå‡
- `plateau_t â‰ˆ 100`: æ€§èƒ½å®Œå…¨åœæ»

---

### 1.2 æ“ä½œæ¦‚ç‡

```python
# åŸå§‹æ¦‚ç‡
p_opt_raw = (1 - Î±_s - Î±_m) Â· plateau_t
p_split_raw = Î±_s Â· plateau_t Â· exp(-Î·_s Â· N_s)
p_merge_raw = Î±_m Â· plateau_t Â· exp(-Î·_m Â· N_m)

# å½’ä¸€åŒ–
total = p_opt_raw + p_split_raw + p_merge_raw
p_opt = p_opt_raw / total
p_split = p_split_raw / total
p_merge = p_merge_raw / total

# æ¦‚ç‡é‡‡æ ·
operation = random.choices(
    ['optimize', 'differentiate', 'fuse'],
    weights=[p_opt, p_split, p_merge]
)[0]
```

**å‚æ•°**:
- `Î±_s`: åˆ†åŒ–åŸºç¡€æ¦‚ç‡ (é»˜è®¤: 0.5)
- `Î±_m`: èåˆåŸºç¡€æ¦‚ç‡ (é»˜è®¤: 0.6)
- `Î·_s`: åˆ†åŒ–è¡°å‡å› å­ (é»˜è®¤: 0.03)
- `Î·_m`: èåˆè¡°å‡å› å­ (é»˜è®¤: 0.03)
- `N_s`: ç´¯è®¡åˆ†åŒ–æ¬¡æ•°
- `N_m`: ç´¯è®¡èåˆæ¬¡æ•°

---

### 1.3 åˆ†åŒ–æ½œåŠ›

```python
# å…¨å±€æ€§èƒ½
Acc_global = C_total / N

# ç±»åˆ«æ€§èƒ½
for category k:
    Recall_k = C_k / N_k
    Contrib_k = C_k / N  # ç»å¯¹è´¡çŒ®åº¦(é˜²æ­¢å°ç±»åˆ«åå‘)
    
    # ä¼˜åŠ¿ç±»åˆ«åˆ¤å®š
    if Recall_k > Acc_global:
        Score_split(k) = Contrib_k Ã— (Recall_k - Acc_global)
    else:
        Score_split(k) = 0

# å·¥ä½œæµåˆ†åŒ–æ½œåŠ›
Split_Potential(W) = max_k(Score_split(k))

# é€‰æ‹©ç­–ç•¥ï¼ˆæƒè¡¡æ½œåŠ›å’Œå‡†ç¡®ç‡ï¼‰
x = Split_Potential(W) / max(Split_Potential)  # å½’ä¸€åŒ–
Adjusted_Score(W) = Î± Â· x + (1-Î±) Â· Acc_global
selected_workflow = argmax_W(Adjusted_Score(W))
target_category = argmax_k(Score_split(k) for selected_workflow)

# Î±: æ½œåŠ›æƒé‡ (é»˜è®¤0.5)
#   - Î±=1.0: åªçœ‹æ½œåŠ›
#   - Î±=0.5: å¹³è¡¡
#   - Î±=0.0: åªçœ‹å‡†ç¡®ç‡
```

**ç¬¦å·**:
- `C_total`: æ€»ç­”å¯¹é¢˜ç›®æ•°
- `N`: æ€»é¢˜ç›®æ•°
- `C_k`: ç±»åˆ«kç­”å¯¹é¢˜ç›®æ•°
- `Î±`: åˆ†åŒ–æ½œåŠ›æƒé‡ (é»˜è®¤: 0.5)
- `N_k`: ç±»åˆ«kæ€»é¢˜ç›®æ•°

---

### 1.4 èåˆäº’è¡¥æ€§

```python
# Pairwiseäº’è¡¥æ€§
C_i = {p: W_i correct on p}
C_j = {p: W_j correct on p}

Î¦_pair(i, j) = |C_i âŠ• C_j|
             = |C_i \ C_j| + |C_j \ C_i|

# Tripletäº’è¡¥æ€§
for each problem p:
    n_correct(p) = |{i: W_i correct on p}|

Î¦_triple(i,j,k) = |{p: n_correct(p) = 1}| + 
                  |{p: n_correct(p) = 2}|

# æ€»èåˆæ½œåŠ›
Î¦_merge(i,j,k) = Î²_p Â· (Î¦_pair(i,j) + Î¦_pair(j,k) + Î¦_pair(i,k)) +
                 Î²_t Â· Î¦_triple(i,j,k)

# é€‰æ‹©
best_triple = argmax_{i,j,k}(Î¦_merge(i,j,k))
```

**å‚æ•°**:
- `Î²_p`: Pairwiseæƒé‡ (ç†è®º: 0.4, ä»£ç : 0.4)
- `Î²_t`: Tripletæƒé‡ (ç†è®º: 0.3, ä»£ç : 0.6 âš ï¸)

---

## 2. å…³é”®å‚æ•°è¡¨

### 2.1 åœæ»æ£€æµ‹

| å‚æ•° | ç¬¦å· | é»˜è®¤å€¼ | èŒƒå›´ | è¯´æ˜ |
|------|------|--------|------|------|
| `sliding_window_k` | k | 3 | 2-5 | æ»‘åŠ¨çª—å£å¤§å° |
| `stagnation_sensitivity_kappa` | Îº | 80.0 | 50-100 | åœæ»æ•æ„Ÿåº¦ |

**è°ƒå‚å»ºè®®**:
- **k=2**: å¯¹çŸ­æœŸæ³¢åŠ¨æ•æ„Ÿ
- **k=3**: å¹³è¡¡ (æ¨è)
- **k=5**: å¯¹é•¿æœŸè¶‹åŠ¿æ•æ„Ÿ

- **Îº=50**: æ›´å®¹æ˜“åˆ¤å®šä¸ºåœæ»
- **Îº=80**: å¹³è¡¡ (æ¨è)
- **Îº=100**: æ›´éš¾åˆ¤å®šä¸ºåœæ»

---

### 2.2 æ“ä½œæ¦‚ç‡

| å‚æ•° | ç¬¦å· | ç†è®ºå€¼ | ä»£ç é»˜è®¤ | èŒƒå›´ | è¯´æ˜ |
|------|------|--------|----------|------|------|
| `alpha_s` | Î±_s | 0.3 | 0.5 âš ï¸ | 0.1-0.5 | åˆ†åŒ–åŸºç¡€æ¦‚ç‡ |
| `alpha_m` | Î±_m | 0.4 | 0.6 âš ï¸ | 0.1-0.6 | èåˆåŸºç¡€æ¦‚ç‡ |
| `eta_s` | Î·_s | 0.1 | 0.03 âš ï¸ | 0.01-0.2 | åˆ†åŒ–è¡°å‡å› å­ |
| `eta_m` | Î·_m | 0.1 | 0.03 âš ï¸ | 0.01-0.2 | èåˆè¡°å‡å› å­ |

**è°ƒå‚å»ºè®®**:

**ä¿å®ˆç­–ç•¥** (å°‘åˆ†åŒ–/èåˆ):
```python
alpha_s = 0.2
alpha_m = 0.3
eta_s = 0.15
eta_m = 0.15
```

**æ¿€è¿›ç­–ç•¥** (å¤šåˆ†åŒ–/èåˆ):
```python
alpha_s = 0.5
alpha_m = 0.6
eta_s = 0.02
eta_m = 0.02
```

**å¹³è¡¡ç­–ç•¥** (æ¨è):
```python
alpha_s = 0.3-0.4
alpha_m = 0.4-0.5
eta_s = 0.05-0.1
eta_m = 0.05-0.1
```

---

### 2.3 åˆ†åŒ–é€‰æ‹©

| å‚æ•° | ç¬¦å· | é»˜è®¤å€¼ | èŒƒå›´ | è¯´æ˜ |
|------|------|--------|------|------|
| `alpha_split_potential` | Î± | 0.5 | 0.0-1.0 | åˆ†åŒ–æ½œåŠ›æƒé‡ |

**è°ƒå‚å»ºè®®**:
- **Î±=1.0**: åªçœ‹åˆ†åŒ–æ½œåŠ› (å¯èƒ½é€‰æ‹©"åç§‘"ä½†æ€§èƒ½å·®çš„)
- **Î±=0.5**: å¹³è¡¡æ½œåŠ›å’Œå‡†ç¡®ç‡ (æ¨è)
- **Î±=0.0**: åªçœ‹å‡†ç¡®ç‡ (é€€åŒ–ä¸ºé€‰æœ€ä½³workflow)

**æƒè¡¡å…¬å¼**:
```
Adjusted_Score = Î± Ã— (Potential/MaxPotential) + (1-Î±) Ã— Accuracy
```

---

### 2.4 èåˆé€‰æ‹©

| å‚æ•° | ç¬¦å· | ç†è®ºå€¼ | ä»£ç é»˜è®¤ | è¯´æ˜ |
|------|------|--------|----------|------|
| `beta_pair` | Î²_p | 0.4 | 0.4 âœ… | Pairwiseæƒé‡ |
| `beta_triple` | Î²_t | 0.3 | 0.6 âš ï¸ | Tripletæƒé‡ |
| `alpha_U` | Î±_U | - | 0.6 | äº’è¡¥æ€§æƒé‡ |
| `alpha_I` | Î±_I | - | 0.4 | ä¸€è‡´æ€§æƒé‡ |
| `gamma_pair` | Î³_p | - | 0.7 | Pairäº¤é›†æƒé‡ |
| `gamma_triple` | Î³_t | - | 0.3 | Tripleäº¤é›†æƒé‡ |

**è°ƒå‚å»ºè®®**:

**å¼ºè°ƒå·®å¼‚** (å·®å¼‚å¤§çš„workflows):
```python
beta_pair = 0.5
beta_triple = 0.3
```

**å¼ºè°ƒååŒ** (éœ€è¦æŠ•ç¥¨çš„åœºæ™¯):
```python
beta_pair = 0.3
beta_triple = 0.5
```

---

### 2.5 å…¶ä»–å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `max_rounds` | 20 | æœ€å¤§ä¼˜åŒ–è½®æ•° |
| `validation_rounds` | 5 | éªŒè¯è½®æ•° |
| `sample` | -1 | è®­ç»ƒæ ·æœ¬æ•° (-1=å…¨éƒ¨) |
| `max_envelope_workflows` | 3 | åŒ…ç»œçº¿æœ€å¤§å¤§å° |
| `fusion_score_threshold` | 0.0 | èåˆæœ€å°åˆ†æ•°æå‡ |
| `alpha_split_potential` | 0.5 | åˆ†åŒ–æ½œåŠ›æƒé‡ |

---

## 3. å¸¸ç”¨å‘½ä»¤

### 3.1 è¿è¡Œä¼˜åŒ–

```bash
# åŸºæœ¬è¿è¡Œ
python run.py --dataset MATH --max_rounds 20

# è‡ªå®šä¹‰å‚æ•°
python run.py \
  --dataset MATH \
  --max_rounds 30 \
  --sliding_window_k 3 \
  --alpha_s 0.3 \
  --alpha_m 0.4 \
  --eta_s 0.1 \
  --eta_m 0.1 \
  --beta_pair 0.4 \
  --beta_triple 0.3 \
  --alpha_split_potential 0.5

# ä¿å®ˆç­–ç•¥
python run.py \
  --dataset MATH \
  --alpha_s 0.2 \
  --alpha_m 0.3 \
  --eta_s 0.15 \
  --eta_m 0.15

# æ¿€è¿›ç­–ç•¥
python run.py \
  --dataset MATH \
  --alpha_s 0.5 \
  --alpha_m 0.6 \
  --eta_s 0.02 \
  --eta_m 0.02
```

---

### 3.2 æ—¥å¿—æŸ¥è¯¢

```bash
# æŸ¥çœ‹åœæ»åº¦
grep "Plateau" logs/AFlow.log

# æŸ¥çœ‹æ“ä½œæ¦‚ç‡
grep "Operation Probabilities" logs/AFlow.log

# æŸ¥çœ‹é€‰æ‹©çš„æ“ä½œ
grep "Selected operation" logs/AFlow.log

# æŸ¥çœ‹è½®æ¬¡åˆ†æ•°
grep "Score for round" logs/AFlow.log

# æŸ¥çœ‹åˆ†åŒ–ä¿¡æ¯
grep "differentiation" logs/AFlow.log -i

# æŸ¥çœ‹èåˆä¿¡æ¯
grep "fusion\|merge" logs/AFlow.log -i

# æŸ¥çœ‹åŒ…ç»œçº¿
grep "Envelope" logs/AFlow.log

# æŸ¥çœ‹äº’è¡¥æ€§
grep "Complementarity\|Î¦_merge" logs/AFlow.log
```

---

### 3.3 æ•°æ®æ£€æŸ¥

```bash
# æŸ¥çœ‹results.json
cat workspace/MATH/workflows/results.json | jq '.'

# æŸ¥çœ‹ç‰¹å®šè½®æ¬¡
cat workspace/MATH/workflows/results.json | \
  jq '.[] | select(.round == 5)'

# æŸ¥çœ‹æ‰€æœ‰è½®æ¬¡åˆ†æ•°
cat workspace/MATH/workflows/results.json | \
  jq '.[] | {round: .round, score: .score, total: .total}'

# æŸ¥çœ‹log.json
cat workspace/MATH/workflows/round_5/log.json | jq '.'

# ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
cat workspace/MATH/workflows/problem_classifications.json | \
  jq '.problem_classifications | group_by(.category) | 
      map({category: .[0].category, count: length})'

# æŸ¥çœ‹æŸè½®çš„ç±»åˆ«ç»Ÿè®¡
cat workspace/MATH/workflows/round_5/log.json | \
  jq 'group_by(.category) | 
      map({category: .[0].category, 
           correct: [.[] | select(.score >= 0.5)] | length,
           total: length})'
```

---

### 3.4 è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥Pythonç¯å¢ƒ
python --version
pip list | grep -E "pydantic|numpy"

# æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
ls workspace/MATH/workflows/round_*/
find workspace/MATH/workflows/ -name "log.json"
find workspace/MATH/workflows/ -name "graph.py"

# éªŒè¯JSONæ ¼å¼
cat workspace/MATH/workflows/results.json | jq empty
cat workspace/MATH/workflows/problem_classifications.json | jq empty

# æ¸…ç†workspace (è°¨æ…!)
rm -rf workspace/MATH/workflows/round_*
# ä¿ç•™templateå’Œproblem_classifications.json

# é‡æ–°å¼€å§‹
python run.py --dataset MATH --initial_round 1
```

---

## 4. å…¸å‹é—®é¢˜è¯Šæ–­

### 4.1 æ“ä½œæ¦‚ç‡å…¨ä¸º0

**ç—‡çŠ¶**:
```
Operation Probabilities (Round 4):
  optimize: 0.0000 (0.00%)
  differentiate: 0.0000 (0.00%)  
  fuse: 0.0000 (0.00%)
```

**åŸå› **:
- `plateau_t = 0` (æ€§èƒ½è¿˜åœ¨æå‡)
- `performance_history` é•¿åº¦ä¸è¶³

**è§£å†³**:
- ç»§ç»­è¿è¡Œ,ç­‰å¾…åœæ»
- æ£€æŸ¥ `performance_history` é•¿åº¦

**éªŒè¯**:
```bash
grep "Plateau" logs/AFlow.log
grep "performance_history length" logs/AFlow.log
```

---

### 4.2 æ— ä¼˜åŠ¿ç±»åˆ«

**ç—‡çŠ¶**:
```
No advantageous specialization found
All categories have Recall <= Acc_global
```

**åŸå› **:
- æ‰€æœ‰ç±»åˆ«è¡¨ç°éƒ½æ¥è¿‘å¹³å‡æ°´å¹³
- æ²¡æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ç±»åˆ«

**è§£å†³**:
- è¿™æ˜¯æ­£å¸¸çš„,ä¸æ˜¯bug
- ç»§ç»­è¿è¡Œ,ç­‰å¾…åˆ†åŒ–æœºä¼š
- æˆ–è€…é™ä½ä¼˜åŠ¿é˜ˆå€¼

**éªŒè¯**:
```bash
# æŸ¥çœ‹ç±»åˆ«ç»Ÿè®¡
cat workspace/MATH/workflows/round_5/log.json | \
  jq 'group_by(.category) | 
      map({category: .[0].category, 
           recall: ([.[] | select(.score >= 0.5)] | length) / length})'
```

---

### 4.3 èåˆå¤±è´¥

**ç—‡çŠ¶**:
```
Insufficient workflows for fusion: found 2, need 3
```

**åŸå› **:
- workflowsæ•°é‡ä¸è¶³3ä¸ª
- åŒ…ç»œçº¿å¤ªå°

**è§£å†³**:
- ç»§ç»­è¿è¡Œ,ç§¯ç´¯æ›´å¤šworkflows
- é™ä½ `max_envelope_workflows`

**éªŒè¯**:
```bash
# ç»Ÿè®¡workflowsæ•°é‡
ls -d workspace/MATH/workflows/round_*/ | wc -l

# æŸ¥çœ‹åŒ…ç»œçº¿
grep "Envelope workflows" logs/AFlow.log
```

---

### 4.4 Categoryæ˜¾ç¤º"unknown"

**ç—‡çŠ¶**:
```json
{
  "problem_id": "problem_0",
  "category": "unknown",
  "score": 1.0
}
```

**åŸå› **:
- `problem_classifications.json` ä¸å­˜åœ¨
- Problem IDä¸åŒ¹é…

**è§£å†³**:
1. âœ… ç¡®ä¿benchmarkså·²ä¿®æ”¹ (æ·»åŠ `_index`å­—æ®µ)
2. ç¬¬ä¸€æ¬¡åˆ†åŒ–æ—¶è‡ªåŠ¨ç”Ÿæˆåˆ†ç±»æ–‡ä»¶
3. æˆ–æ‰‹åŠ¨ç”Ÿæˆ:
```bash
python scripts/problem_classifier.py --dataset MATH
```

**éªŒè¯**:
```bash
# æ£€æŸ¥åˆ†ç±»æ–‡ä»¶
cat workspace/MATH/workflows/problem_classifications.json | \
  jq '.categories'

# æ£€æŸ¥problem_idæ ¼å¼
cat workspace/MATH/workflows/round_5/log.json | \
  jq '.[0].problem_id'
# åº”è¯¥æ˜¯: "problem_0", "problem_1", ...
```

---

## 5. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 5.1 åŠ é€Ÿè¯„ä¼°

```bash
# ä½¿ç”¨æ›´å°‘çš„æ ·æœ¬
python run.py --dataset MATH --sample 50

# å¹¶è¡Œè¯„ä¼° (å¦‚æœæ”¯æŒ)
python run.py --dataset MATH --parallel_workers 4
```

---

### 5.2 å‡å°‘LLMè°ƒç”¨

```bash
# é™ä½èåˆé¢‘ç‡
python run.py --alpha_m 0.2 --eta_m 0.15

# é™ä½åˆ†åŒ–é¢‘ç‡
python run.py --alpha_s 0.2 --eta_s 0.15

# åŒæ—¶é™ä½
python run.py --alpha_s 0.2 --alpha_m 0.2 --eta_s 0.15 --eta_m 0.15
```

---

### 5.3 ç¼“å­˜ä¼˜åŒ–

```python
# åœ¨enhanced_optimizer.pyä¸­æ·»åŠ 
@functools.lru_cache(maxsize=128)
def _load_workflow_category_stats_cached(self, workflow_id):
    """ç¼“å­˜ç‰ˆæœ¬"""
    return self._load_workflow_category_stats(workflow_id)
```

---

## 6. å¸¸è§é”™è¯¯ç 

### 6.1 æ–‡ä»¶ç›¸å…³

| é”™è¯¯ä¿¡æ¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| `FileNotFoundError: log.json` | è½®æ¬¡ç›®å½•ä¸å­˜åœ¨ | æ£€æŸ¥roundè·¯å¾„ |
| `FileNotFoundError: problem_classifications.json` | æœªç”Ÿæˆåˆ†ç±»æ–‡ä»¶ | è¿è¡Œåˆ†åŒ–æˆ–æ‰‹åŠ¨ç”Ÿæˆ |
| `JSONDecodeError` | JSONæ ¼å¼é”™è¯¯ | æ£€æŸ¥æ–‡ä»¶å†…å®¹ |

---

### 6.2 è®¡ç®—ç›¸å…³

| é”™è¯¯ä¿¡æ¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| `ZeroDivisionError` | é™¤é›¶é”™è¯¯ | æ£€æŸ¥é™¤æ³•ä¿æŠ¤ |
| `IndexError: list index out of range` | åˆ—è¡¨ä¸ºç©º | æ£€æŸ¥é•¿åº¦ä¿æŠ¤ |
| `KeyError: 'category'` | å­—æ®µç¼ºå¤± | æ£€æŸ¥æ•°æ®æ ¼å¼ |

---

### 6.3 é€»è¾‘ç›¸å…³

| é”™è¯¯ä¿¡æ¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| `No workflows to optimize` | åˆå§‹åŒ–å¤±è´¥ | æ£€æŸ¥template/ |
| `Operation failed, retrying...` | LLMç”Ÿæˆå¤±è´¥ | æ£€æŸ¥LLMé…ç½® |
| `Evaluation failed` | è¯„ä¼°é”™è¯¯ | æ£€æŸ¥benchmarké…ç½® |

---

## 7. æœ€ä½³å®è·µ

### 7.1 å¯åŠ¨æ–°å®éªŒ

```bash
# 1. æ¸…ç†æ—§æ•°æ®
rm -rf workspace/MATH/workflows/round_*
rm workspace/MATH/workflows/results.json
rm workspace/MATH/workflows/processed_experience.json

# ä¿ç•™
# - workspace/MATH/workflows/template/
# - workspace/MATH/workflows/problem_classifications.json (å¯é€‰)

# 2. é…ç½®å‚æ•°
python run.py \
  --dataset MATH \
  --max_rounds 30 \
  --alpha_s 0.3 \
  --alpha_m 0.4 \
  --sliding_window_k 3

# 3. ç›‘æ§æ—¥å¿—
tail -f logs/AFlow.log
```

---

### 7.2 æ¢å¤ä¸­æ–­çš„å®éªŒ

```bash
# æŸ¥çœ‹æœ€åä¸€è½®
cat workspace/MATH/workflows/results.json | jq '.[-1]'

# ä»æœ€åä¸€è½®+1ç»§ç»­
last_round=$(cat workspace/MATH/workflows/results.json | jq '.[-1].round')
next_round=$((last_round + 1))

python run.py \
  --dataset MATH \
  --initial_round $next_round \
  --max_rounds 30
```

---

### 7.3 æ€§èƒ½åˆ†æ

```bash
# ç”Ÿæˆåˆ†æ•°æ›²çº¿
cat workspace/MATH/workflows/results.json | \
  jq -r '.[] | "\(.round),\(.score)"' > scores.csv

# ç”¨Pythonç»˜å›¾
python -c "
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('scores.csv', names=['round', 'score'])
plt.plot(df['round'], df['score'], marker='o')
plt.xlabel('Round')
plt.ylabel('Score')
plt.title('Optimization Progress')
plt.savefig('progress.png')
"

# ç»Ÿè®¡æ“ä½œåˆ†å¸ƒ
grep "Selected operation" logs/AFlow.log | \
  awk '{print $NF}' | \
  sort | uniq -c

# è¾“å‡ºç¤ºä¾‹:
#   15 optimize
#    3 differentiate
#    2 fuse
```

---

## 8. å¿«é€Ÿæ•…éšœæ’é™¤

### 8.1 5åˆ†é’Ÿæ£€æŸ¥æ¸…å•

```bash
# 1. æ£€æŸ¥ç¯å¢ƒ
python --version  # Python 3.8+
pip show pydantic numpy  # ä¾èµ–å®‰è£…

# 2. æ£€æŸ¥æ–‡ä»¶
ls workspace/MATH/workflows/template/
ls workspace/MATH/workflows/round_*/

# 3. æ£€æŸ¥æ—¥å¿—
tail -100 logs/AFlow.log

# 4. æ£€æŸ¥é…ç½®
cat config/config.yaml | grep -A5 llm

# 5. æ£€æŸ¥æ•°æ®
cat workspace/MATH/workflows/results.json | jq empty
```

---

### 8.2 å¸¸è§é—®é¢˜å¿«é€Ÿä¿®å¤

**é—®é¢˜**: æ‰€æœ‰ç±»åˆ«æ˜¾ç¤º"unknown"
```bash
# ä¿®å¤
python scripts/problem_classifier.py --dataset MATH

# éªŒè¯
cat workspace/MATH/workflows/problem_classifications.json | \
  jq '.categories'
```

**é—®é¢˜**: èåˆå¤±è´¥ "found 2, need 3"
```bash
# æ£€æŸ¥
ls -d workspace/MATH/workflows/round_*/ | wc -l

# å¦‚æœ < 3, ç»§ç»­è¿è¡Œç§¯ç´¯workflows
# å¦‚æœ >= 3, æ£€æŸ¥åŒ…ç»œçº¿æ—¥å¿—
grep "Envelope" logs/AFlow.log
```

**é—®é¢˜**: æ¦‚ç‡å…¨ä¸º0
```bash
# æ£€æŸ¥åœæ»åº¦
grep "Plateau" logs/AFlow.log

# å¦‚æœ plateau = 0, ç»§ç»­è¿è¡Œç­‰å¾…åœæ»
# å¦‚æœ plateau > 0, æ£€æŸ¥æ“ä½œè®¡æ•°
grep "N_s\|N_m" logs/AFlow.log
```

---

## 9. é…ç½®æ¨¡æ¿

### 9.1 å¿«é€Ÿå¯åŠ¨

```yaml
# config/quick_start.yaml
dataset: MATH
max_rounds: 20
sliding_window_k: 3
stagnation_sensitivity_kappa: 80.0

# å¹³è¡¡ç­–ç•¥
alpha_s: 0.3
alpha_m: 0.4
eta_s: 0.1
eta_m: 0.1

beta_pair: 0.4
beta_triple: 0.3
```

```bash
python run.py --config config/quick_start.yaml
```

---

### 9.2 ä¿å®ˆç­–ç•¥

```yaml
# config/conservative.yaml
dataset: MATH
max_rounds: 30

# å°‘åˆ†åŒ–/èåˆ
alpha_s: 0.2
alpha_m: 0.3
eta_s: 0.15
eta_m: 0.15

# æ›´ä¸¥æ ¼çš„åœæ»åˆ¤å®š
stagnation_sensitivity_kappa: 100.0
sliding_window_k: 5
```

---

### 9.3 æ¿€è¿›ç­–ç•¥

```yaml
# config/aggressive.yaml
dataset: MATH
max_rounds: 30

# å¤šåˆ†åŒ–/èåˆ
alpha_s: 0.5
alpha_m: 0.6
eta_s: 0.02
eta_m: 0.02

# æ›´æ•æ„Ÿçš„åœæ»åˆ¤å®š
stagnation_sensitivity_kappa: 60.0
sliding_window_k: 2
```

---

## 10. ç›¸å…³æ–‡æ¡£ç´¢å¼•

### 10.1 æ ¸å¿ƒæ–‡æ¡£

- **[ç³»ç»Ÿæ¶æ„æ€»è§ˆ](SYSTEM_ARCHITECTURE.md)**: å®Œæ•´ç³»ç»Ÿè®¾è®¡
- **[ä¼˜åŒ–æ“ä½œè¯¦è§£](OPTIMIZE_OPERATION.md)**: OPTIMIZEæ“ä½œ
- **[åˆ†åŒ–æ“ä½œè¯¦è§£](DIFFERENTIATION_OPERATION.md)**: DIFFERENTIATEæ“ä½œ
- **[èåˆæ“ä½œè¯¦è§£](FUSION_OPERATION.md)**: FUSEæ“ä½œ
- **[ä»£ç ä¸€è‡´æ€§æ£€æŸ¥](CODE_CONSISTENCY_CHECK.md)**: å®ç°éªŒè¯

---

### 10.2 æŒ‰éœ€æŸ¥é˜…

**æƒ³è¦äº†è§£...**

- **æ•´ä½“æµç¨‹**: [ç³»ç»Ÿæ¶æ„æ€»è§ˆ](SYSTEM_ARCHITECTURE.md) Â§ æ§åˆ¶æµç¨‹
- **åœæ»æ£€æµ‹**: [ç³»ç»Ÿæ¶æ„æ€»è§ˆ](SYSTEM_ARCHITECTURE.md) Â§ åœæ»æ£€æµ‹
- **æ“ä½œé€‰æ‹©**: [ç³»ç»Ÿæ¶æ„æ€»è§ˆ](SYSTEM_ARCHITECTURE.md) Â§ æ“ä½œé€‰æ‹©
- **ä¼˜åŒ–ç»†èŠ‚**: [ä¼˜åŒ–æ“ä½œè¯¦è§£](OPTIMIZE_OPERATION.md)
- **åˆ†åŒ–ç®—æ³•**: [åˆ†åŒ–æ“ä½œè¯¦è§£](DIFFERENTIATION_OPERATION.md) Â§ æ ¸å¿ƒç®—æ³•
- **èåˆç®—æ³•**: [èåˆæ“ä½œè¯¦è§£](FUSION_OPERATION.md) Â§ æ ¸å¿ƒç®—æ³•
- **å‚æ•°ä¸ä¸€è‡´**: [ä»£ç ä¸€è‡´æ€§æ£€æŸ¥](CODE_CONSISTENCY_CHECK.md) Â§ è¶…å‚æ•°å¯¹ç…§
- **Bugä¿®å¤**: [ä»£ç ä¸€è‡´æ€§æ£€æŸ¥](CODE_CONSISTENCY_CHECK.md) Â§ æ½œåœ¨Bug

---

### 10.3 å¿«é€Ÿå¯¼èˆª

```
é—®é¢˜è¯Šæ–­è·¯å¾„:
  æ“ä½œæ¦‚ç‡ä¸º0 â†’ ç³»ç»Ÿæ¶æ„ Â§ åœæ»æ£€æµ‹
  æ— ä¼˜åŠ¿ç±»åˆ« â†’ åˆ†åŒ–æ“ä½œ Â§ åˆ†åŒ–æ½œåŠ›è®¡ç®—
  èåˆå¤±è´¥ â†’ èåˆæ“ä½œ Â§ åŒ…ç»œçº¿é€‰æ‹©
  Category unknown â†’ ä»£ç ä¸€è‡´æ€§ Â§ æ•°æ®ç»“æ„

ç®—æ³•ç»†èŠ‚è·¯å¾„:
  åœæ»åº¦å…¬å¼ â†’ å¿«é€Ÿå‚è€ƒ Â§ æ ¸å¿ƒå…¬å¼ â†’ ç³»ç»Ÿæ¶æ„ Â§ åœæ»æ£€æµ‹
  åˆ†åŒ–å…¬å¼ â†’ å¿«é€Ÿå‚è€ƒ Â§ æ ¸å¿ƒå…¬å¼ â†’ åˆ†åŒ–æ“ä½œ Â§ æ ¸å¿ƒç®—æ³•
  èåˆå…¬å¼ â†’ å¿«é€Ÿå‚è€ƒ Â§ æ ¸å¿ƒå…¬å¼ â†’ èåˆæ“ä½œ Â§ æ ¸å¿ƒç®—æ³•

å‚æ•°è°ƒä¼˜è·¯å¾„:
  æŸ¥çœ‹å½“å‰å€¼ â†’ å¿«é€Ÿå‚è€ƒ Â§ å…³é”®å‚æ•°è¡¨
  ç†è§£å«ä¹‰ â†’ ç³»ç»Ÿæ¶æ„ / æ“ä½œè¯¦è§£
  æ£€æŸ¥ä¸€è‡´æ€§ â†’ ä»£ç ä¸€è‡´æ€§ Â§ è¶…å‚æ•°å¯¹ç…§
  è°ƒæ•´å»ºè®® â†’ å¿«é€Ÿå‚è€ƒ Â§ å¸¸ç”¨å‘½ä»¤
```

---

## 11. é™„å½•

### 11.1 ç¬¦å·è¡¨

| ç¬¦å· | å«ä¹‰ | å–å€¼èŒƒå›´ |
|------|------|----------|
| t | å½“å‰è½®æ¬¡ | 1, 2, 3, ... |
| k | æ»‘åŠ¨çª—å£å¤§å° | é€šå¸¸ 2-5 |
| Îº | åœæ»æ•æ„Ÿåº¦ | é€šå¸¸ 50-100 |
| plateau_t | åœæ»åº¦ | 0-100 |
| Î±_s | åˆ†åŒ–åŸºç¡€æ¦‚ç‡ | 0-1 |
| Î±_m | èåˆåŸºç¡€æ¦‚ç‡ | 0-1 |
| Î·_s | åˆ†åŒ–è¡°å‡å› å­ | 0-1 |
| Î·_m | èåˆè¡°å‡å› å­ | 0-1 |
| N_s | ç´¯è®¡åˆ†åŒ–æ¬¡æ•° | 0, 1, 2, ... |
| N_m | ç´¯è®¡èåˆæ¬¡æ•° | 0, 1, 2, ... |
| Î²_p | Pairwiseæƒé‡ | 0-1 |
| Î²_t | Tripletæƒé‡ | 0-1 |
| Î¦_merge | èåˆæ½œåŠ› | >=0 |

---

### 11.2 ç¼©å†™è¡¨

| ç¼©å†™ | å…¨ç§° | å«ä¹‰ |
|------|------|------|
| W | Workflow | å·¥ä½œæµ |
| CoT | Chain-of-Thought | æ€ç»´é“¾ |
| PoT | Program-of-Thought | ç¨‹åºæ€ç»´é“¾ |
| LLM | Large Language Model | å¤§è¯­è¨€æ¨¡å‹ |
| Acc | Accuracy | å‡†ç¡®ç‡ |
| Contrib | Contribution | è´¡çŒ®åº¦ |
| Î¦ | Phi | äº’è¡¥æ€§/æ½œåŠ› |
| âŠ• | XOR | å¯¹ç§°å·® |

---

### 11.3 å…³é”®æ–‡ä»¶è·¯å¾„

```
workspace/DATASET/workflows/
â”œâ”€â”€ template/                          # åˆå§‹workflowæ¨¡æ¿
â”‚   â”œâ”€â”€ op_prompt.py
â”‚   â”œâ”€â”€ operator.py
â”‚   â”œâ”€â”€ operator_an.py
â”‚   â””â”€â”€ operator.json
â”œâ”€â”€ round_1/                           # ç¬¬1è½® (åˆå§‹workflowè¯„ä¼°)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ prompt.py
â”‚   â””â”€â”€ log.json
â”œâ”€â”€ round_2/                           # ç¬¬2è½® (ç¬¬ä¸€æ¬¡ä¼˜åŒ–)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ prompt.py
â”‚   â””â”€â”€ log.json
â”œâ”€â”€ ...
â”œâ”€â”€ results.json                       # æ‰€æœ‰è½®æ¬¡çš„æ€§èƒ½æ±‡æ€»
â”œâ”€â”€ processed_experience.json          # ä¼˜åŒ–ç»éªŒ
â””â”€â”€ problem_classifications.json       # é—®é¢˜åˆ†ç±» (é¦–æ¬¡åˆ†åŒ–æ—¶ç”Ÿæˆ)
```

---

## 12. è”ç³»ä¸è´¡çŒ®

### 12.1 æŠ¥å‘Šé—®é¢˜

```bash
# æ”¶é›†è¯Šæ–­ä¿¡æ¯
python run.py --dataset MATH --debug > debug.log 2>&1

# æ‰“åŒ…ç›¸å…³æ–‡ä»¶
tar -czf debug_package.tar.gz \
  debug.log \
  logs/AFlow.log \
  workspace/MATH/workflows/results.json \
  workspace/MATH/workflows/round_*/log.json
```

---

### 12.2 æ–‡æ¡£æ›´æ–°

æœ¬æ–‡æ¡£é›†åŒ…å«:
1. **SYSTEM_ARCHITECTURE.md**: ç³»ç»Ÿæ¶æ„æ€»è§ˆ
2. **OPTIMIZE_OPERATION.md**: ä¼˜åŒ–æ“ä½œè¯¦è§£
3. **DIFFERENTIATION_OPERATION.md**: åˆ†åŒ–æ“ä½œè¯¦è§£
4. **FUSION_OPERATION.md**: èåˆæ“ä½œè¯¦è§£
5. **CODE_CONSISTENCY_CHECK.md**: ä»£ç ä¸€è‡´æ€§æ£€æŸ¥
6. **QUICK_REFERENCE.md**: å¿«é€Ÿå‚è€ƒ (æœ¬æ–‡æ¡£)

æœ€åæ›´æ–°: 2025-12-15

---

**Happy Optimizing! ğŸš€**
